import streamlit as st
import torch
from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM
import warnings
warnings.filterwarnings('ignore')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="GPT Aristotle - –§–∏–ª–æ—Å–æ—Ñ—Å–∫–∏–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ç–µ–∫—Å—Ç–æ–≤",
    page_icon="üèõÔ∏è",
    layout="wide"
)

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ (–∫—ç—à–∏—Ä—É–µ—Ç—Å—è)
@st.cache_resource
def load_model():
    try:
        model_name = "zhuu4/GPT_aristotle"
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        
        # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∞ GPU —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –ø–∞–º—è—Ç–∏
        try:
            model = AutoModelForCausalLM.from_pretrained(
                model_name,
                torch_dtype=torch.float16,
                device_map="auto",
                low_cpu_mem_usage=True
            )
        except:
            # –ï—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –ø–∞–º—è—Ç–∏, –≥—Ä—É–∑–∏–º –Ω–∞ CPU
            model = AutoModelForCausalLM.from_pretrained(model_name)
            
        return tokenizer, model
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return None, None

# –§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞
def generate_text(prompt, max_length, num_sequences, temperature, top_k, top_p, repetition_penalty):
    try:
        tokenizer, model = load_model()
        if tokenizer is None or model is None:
            return ["–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏"]
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω
        generator = pipeline(
            "text-generation",
            model=model,
            tokenizer=tokenizer,
            device=0 if torch.cuda.is_available() else -1,
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
        )
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
        results = generator(
            prompt,
            max_length=max_length,
            num_return_sequences=num_sequences,
            temperature=temperature,
            do_sample=True,
            top_k=top_k,
            top_p=top_p,
            repetition_penalty=repetition_penalty,
            pad_token_id=tokenizer.eos_token_id
        )
        
        return [result['generated_text'] for result in results]
        
    except Exception as e:
        return [f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {str(e)}"]

# –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å
def main():
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    st.title("üèõÔ∏è GPT Aristotle - –§–∏–ª–æ—Å–æ—Ñ—Å–∫–∏–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ç–µ–∫—Å—Ç–æ–≤")
    st.markdown("### –ú–æ–¥–µ–ª—å, –≤–¥–æ—Ö–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –º—É–¥—Ä–æ—Å—Ç—å—é –ê—Ä–∏—Å—Ç–æ—Ç–µ–ª—è")
    
    # –°–∞–π–¥–±–∞—Ä —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
    st.sidebar.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
    
    # –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–º–ø—Ç–æ–≤
    example_prompts = [
        "–û —Å–º—ã—Å–ª–µ –∂–∏–∑–Ω–∏ –ê—Ä–∏—Å—Ç–æ—Ç–µ–ª—å –≥–æ–≤–æ—Ä–∏–ª:",
        "–î–æ–±—Ä–æ–¥–µ—Ç–µ–ª—å, —Å–æ–≥–ª–∞—Å–Ω–æ —Ñ–∏–ª–æ—Å–æ—Ñ–∏–∏, –µ—Å—Ç—å",
        "–û –ø–æ–ª–∏—Ç–∏–∫–µ –∏ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ:",
        "–ü—Ä–∏—Ä–æ–¥–∞ —á–µ–ª–æ–≤–µ–∫–∞ –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤",
        "–ó–Ω–∞–Ω–∏–µ –∏ –º—É–¥–Ω–æ—Å—Ç—å –æ—Ç–ª–∏—á–∞—é—Ç—Å—è —Ç–µ–º, —á—Ç–æ"
    ]
    
    # –ü—Ä–æ–º–ø—Ç
    prompt = st.text_area(
        "üìù –í–≤–µ–¥–∏—Ç–µ —Ñ–∏–ª–æ—Å–æ—Ñ—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç:",
        value="–û —Å–º—ã—Å–ª–µ –∂–∏–∑–Ω–∏ –ê—Ä–∏—Å—Ç–æ—Ç–µ–ª—å –≥–æ–≤–æ—Ä–∏–ª:",
        height=100,
        help="–ù–∞—á–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–∏–ª–æ—Å–æ—Ñ—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"
    )
    
    # –ö–Ω–æ–ø–∫–∏ –±—ã—Å—Ç—Ä—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤
    st.write("üöÄ –ë—ã—Å—Ç—Ä—ã–µ –ø—Ä–æ–º–ø—Ç—ã:")
    cols = st.columns(len(example_prompts))
    for i, example in enumerate(example_prompts):
        with cols[i]:
            if st.button(example[:20] + "...", key=f"prompt_{i}"):
                st.session_state.prompt = example
                st.rerun()
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        max_length = st.slider(
            "üìè –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞:",
            min_value=50,
            max_value=500,
            value=200,
            step=50,
            help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"
        )
        
        num_sequences = st.slider(
            "üî¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤:",
            min_value=1,
            max_value=5,
            value=1,
            help="–°–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —Ç–µ–∫—Å—Ç–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å"
        )
    
    with col2:
        temperature = st.slider(
            "üé≤ –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞:",
            min_value=0.1,
            max_value=2.0,
            value=0.8,
            step=0.1,
            help="–ß–µ–º –≤—ã—à–µ, —Ç–µ–º –±–æ–ª–µ–µ —Ç–≤–æ—Ä—á–µ—Å–∫–∏–π —Ç–µ–∫—Å—Ç"
        )
        
        top_k = st.slider(
            "üéØ Top-k:",
            min_value=0,
            max_value=100,
            value=40,
            help="–û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –≤—ã–±–æ—Ä —Ç–æ–ø-k —Ç–æ–∫–µ–Ω–∞–º–∏ (0 = –æ—Ç–∫–ª—é—á–µ–Ω–æ)"
        )
    
    with col3:
        top_p = st.slider(
            "üìä Top-p:",
            min_value=0.0,
            max_value=1.0,
            value=0.85,
            step=0.05,
            help="Nucleus sampling - –≤—ã–±–æ—Ä –∏–∑ —Ç–æ–ø-p –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π"
        )
        
        repetition_penalty = st.slider(
            "üö´ –®—Ç—Ä–∞—Ñ –∑–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è:",
            min_value=1.0,
            max_value=2.0,
            value=1.1,
            step=0.1,
            help="–ß–µ–º –≤—ã—à–µ, —Ç–µ–º –º–µ–Ω—å—à–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π –≤ —Ç–µ–∫—Å—Ç–µ"
        )
    
    # –ö–Ω–æ–ø–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    if st.button("üèõÔ∏è –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ñ–∏–ª–æ—Å–æ—Ñ—Å–∫–∏–π —Ç–µ–∫—Å—Ç", type="primary", use_container_width=True):
        if not prompt.strip():
            st.warning("‚ö†Ô∏è –í–≤–µ–¥–∏—Ç–µ –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
            return
            
        with st.spinner("–†–∞–∑–º—ã—à–ª—è–µ–º –Ω–∞–¥ —Ç–µ–∫—Å—Ç–æ–º..."):
            results = generate_text(
                prompt, max_length, num_sequences, 
                temperature, top_k, top_p, repetition_penalty
            )
        
        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        st.success("‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        
        for i, text in enumerate(results, 1):
            with st.expander(f"üìú –§–∏–ª–æ—Å–æ—Ñ—Å–∫–∏–π —Ç–µ–∫—Å—Ç {i}", expanded=True):
                st.text_area(
                    f"–¢–µ–∫—Å—Ç {i}",
                    value=text,
                    height=250,
                    key=f"result_{i}",
                    label_visibility="collapsed"
                )
                
                # –ö–Ω–æ–ø–∫–∞ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è
                st.code(text, language="text")
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                chars = len(text)
                words = len(text.split())
                st.caption(f"üìä –°–∏–º–≤–æ–ª–æ–≤: {chars}, –°–ª–æ–≤: {words}")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤ —Å–∞–π–¥–±–∞—Ä–µ
    st.sidebar.markdown("---")
    st.sidebar.header("‚ÑπÔ∏è –û –º–æ–¥–µ–ª–∏")
    st.sidebar.info("""
    **–ú–æ–¥–µ–ª—å:** GPT Aristotle  
    **–ë–∞–∑–∞:** sberbank-ai/rugpt3small_based_on_gpt2  
    **–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è:** –§–∏–ª–æ—Å–æ—Ñ—Å–∫–∏–µ —Ç–µ–∫—Å—Ç—ã –≤ —Å—Ç–∏–ª–µ –ê—Ä–∏—Å—Ç–æ—Ç–µ–ª—è  
    **–Ø–∑—ã–∫:** –†—É—Å—Å–∫–∏–π
    """)
    
    st.sidebar.markdown("---")
    st.sidebar.header("üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
    st.sidebar.success("""
    ‚Ä¢ –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: 0.7-0.9  
    ‚Ä¢ Top-p: 0.8-0.9  
    ‚Ä¢ –î–ª–∏–Ω–∞: 150-300 —Ç–æ–∫–µ–Ω–æ–≤
    """)
    
    # –°—Ç–∞—Ç—É—Å GPU
    if torch.cuda.is_available():
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        st.sidebar.success(f"‚úÖ GPU –¥–æ—Å—Ç—É–ø–µ–Ω ({gpu_memory:.1f} GB)")
    else:
        st.sidebar.warning("‚ö†Ô∏è GPU –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")

if __name__ == "__main__":
    main()