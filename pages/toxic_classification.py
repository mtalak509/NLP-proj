import streamlit as st
import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import sys
import os
import matplotlib.pyplot as plt
import numpy as np
from models.RuBert.func_tools import get_toxic_classification_with_attention, merge_subtokens
import pandas as pd

# ===== –ù–ê–°–¢–†–û–ô–ö–ê –°–¢–†–ê–ù–ò–¶–´ =====
st.set_page_config(
    page_title="üîç –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¢–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏",
    page_icon="üö´",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ===== CSS –°–¢–ò–õ–ò =====
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        font-weight: bold;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #2e86ab;
        margin-bottom: 1rem;
        font-weight: 600;
    }
    .result-box {
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
        border-left: 5px solid;
    }
    .toxic-result {
        background-color: #ffebee;
        border-left-color: #f44336;
    }
    .non-toxic-result {
        background-color: #e8f5e8;
        border-left-color: #4caf50;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 10px;
        text-align: center;
    }
    .attention-bar {
        height: 8px;
        background: linear-gradient(90deg, #4caf50, #ff9800, #f44336);
        border-radius: 4px;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ===== –ó–ê–ì–û–õ–û–í–û–ö =====
st.markdown('<div class="main-header">üîç –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¢–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏</div>', unsafe_allow_html=True)
st.markdown("### –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–æ–∫—Å–∏—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ —Å –ø–æ–º–æ—â—å—é AI")

# ===== –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ò =====
checkpoint = torch.load(
            'models/RuBert/rubert_model_losss_optimized.pth', 
            map_location=torch.device('cpu')
        )

@st.cache_resource
def load_model_and_tokenizer():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    with st.spinner('üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥'):
        tokenizer = AutoTokenizer.from_pretrained("cointegrated/rubert-tiny-toxicity")
        model = AutoModelForSequenceClassification.from_pretrained("cointegrated/rubert-tiny-toxicity")
        model.classifier = nn.Linear(312, 2)
        # checkpoint = torch.load(
        #     'models/RuBert/rubert_model_losss_optimized.pth', 
        #     map_location=torch.device('cpu')
        # )
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
    return model, tokenizer

# ===== –§–£–ù–ö–¶–ò–Ø –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ò =====
def create_attention_visualization(result):
    """–°–æ–∑–¥–∞–µ—Ç –∫—Ä–∞—Å–∏–≤—É—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é attention –≤–µ—Å–æ–≤"""
    words, merged_attention = merge_subtokens(result['tokens'], result['attention_weights'])
    
    # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫
    fig, ax = plt.subplots(figsize=(12, 6))
    
    # –¶–≤–µ—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–∞–∂–Ω–æ—Å—Ç–∏
    mean_attention = np.mean(merged_attention)
    colors = ['#ff6b6b' if w > mean_attention * 1.5 else 
              '#ffa726' if w > mean_attention else 
              '#4ecdc4' for w in merged_attention]
    
    bars = ax.bar(range(len(words)), merged_attention, color=colors, alpha=0.8, edgecolor='white', linewidth=1)
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥—Ä–∞—Ñ–∏–∫–∞
    ax.set_xticks(range(len(words)))
    ax.set_xticklabels(words, rotation=45, ha='right', fontsize=12)
    ax.set_ylabel('Attention Weight', fontsize=12, fontweight='bold')
    ax.set_title('üîç Attention Analysis - –ö–∞–∫–∏–µ —Å–ª–æ–≤–∞ –≤–∞–∂–Ω—ã –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –º–æ–¥–µ–ª–∏', 
                 fontsize=14, fontweight='bold', pad=20)
    ax.grid(True, alpha=0.3, axis='y')
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
    for bar, value in zip(bars, merged_attention):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + 0.001,
                f'{value:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')
    
    # –õ–µ–≥–µ–Ω–¥–∞
    ax.legend(['–í—ã—Å–æ–∫–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å', '–°—Ä–µ–¥–Ω—è—è –≤–∞–∂–Ω–æ—Å—Ç—å', '–ù–∏–∑–∫–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å'], 
              loc='upper right', framealpha=0.9)
    
    plt.tight_layout()
    return fig, words, merged_attention

# ===== –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° =====
try:
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    model, tokenizer = load_model_and_tokenizer()
    st.success("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
    
    # –°–∞–π–¥–±–∞—Ä —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
    with st.sidebar:
        st.markdown("## ‚ÑπÔ∏è –û –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏")
        st.info("""
        –≠—Ç–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª—å **RuBERT**, 
        –æ–±—É—á–µ–Ω–Ω—É—é –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å —Ç–æ–∫—Å–∏—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏.
        
        ### –ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç:
        1. –í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –≤ –ø–æ–ª–µ –Ω–∏–∂–µ
        2. –ú–æ–¥–µ–ª—å –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
        3. –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º
        
        ### –ú–µ—Ç—Ä–∏–∫–∏:
        - **Accuracy**: 85%+
        - **F1-Score**: 83%+
        """)
        
        st.markdown("---")
        st.markdown("### üéØ –ü—Ä–∏–º–µ—Ä—ã –¥–ª—è —Ç–µ—Å—Ç–∞:")
        examples = [
            "–°–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–º–æ—â—å, –æ—á–µ–Ω—å –ø–æ–ª–µ–∑–Ω–æ!",
            "–¢—ã –ø–æ–ª–Ω—ã–π –∏–¥–∏–æ—Ç –∏ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–Ω–∏–º–∞–µ—à—å!",
            "–û—Ç–ª–∏—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞, –ø—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –≤ —Ç–æ–º –∂–µ –¥—É—Ö–µ",
            "–í—Å–µ –∫—Ç–æ —Ç–∞–∫ –¥—É–º–∞–µ—Ç - –¥–µ–±–∏–ª—ã –∏ –Ω–µ–¥–æ—É–º–∫–∏"
        ]
        
        for example in examples:
            if st.button(example, key=example):
                st.session_state.text_input = example

    # –û—Å–Ω–æ–≤–Ω–∞—è –æ–±–ª–∞—Å—Ç—å
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown('<div class="sub-header">üìù –í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞</div>', unsafe_allow_html=True)
        
        text_input = st.text_area(
            "",
            value=st.session_state.get('text_input', ''),
            placeholder="–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è –∑–¥–µ—Å—å...",
            height=120,
            key="text_input"
        )
        
        analyze_btn = st.button("üöÄ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç", type="primary", use_container_width=True)

    with col2:
        st.markdown('<div class="sub-header">üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–æ–¥–µ–ª–∏</div>', unsafe_allow_html=True)
        
        

        chart_data = pd.DataFrame({
        'Train Loss': checkpoint['train loss'],
        'Validation Loss': checkpoint['valid loss']})
    
        # –ö—Ä–∞—Å–∏–≤—ã–π line chart
        st.line_chart(
        chart_data,
        color=['#FF6B6B', '#4ECDC4'],  # –ö—Ä–∞—Å–Ω—ã–π –¥–ª—è train, –±–∏—Ä—é–∑–æ–≤—ã–π –¥–ª—è validation
        height=400)

        st.markdown("""
        <div class="metric-card">
            <h3>85.3%</h3>
            <p>F1-Score</p>
        </div>
        """, unsafe_allow_html=True)

        st.markdown("""
        <div class="metric-card">
            <h3>85.1%</h3>
            <p>Accuracy</p>
        </div>
        """, unsafe_allow_html=True)

    # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞
    if analyze_btn and text_input:
        with st.spinner('üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç...'):
            result = get_toxic_classification_with_attention(text_input, model, tokenizer)
            
            # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
            fig, words, attention_weights = create_attention_visualization(result)
            
            # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            st.markdown("---")
            st.markdown('<div class="sub-header">üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞</div>', unsafe_allow_html=True)
            
            # –û—Å–Ω–æ–≤–Ω–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            col_res1, col_res2, col_res3 = st.columns([1, 1, 2])
            
            with col_res1:
                if result['prediction'] == 1:
                    st.markdown("""
                    <div class="result-box toxic-result">
                        <h3>üö® –¢–û–ö–°–ò–ß–ù–´–ô</h3>
                        <p>–¢–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—Å–∫–æ—Ä–±–∏—Ç–µ–ª—å–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è</p>
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.markdown("""
                    <div class="result-box non-toxic-result">
                        <h3>‚úÖ –ù–ï–¢–û–ö–°–ò–ß–ù–´–ô</h3>
                        <p>–¢–µ–∫—Å—Ç –≤–µ–∂–ª–∏–≤—ã–π –∏ —É–≤–∞–∂–∏—Ç–µ–ª—å–Ω—ã–π</p>
                    </div>
                    """, unsafe_allow_html=True)
            
            with col_res2:
                confidence = result['probability']
                st.metric(
                    label="–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏",
                    value=f"{confidence:.1%}",
                    delta="–≤—ã—Å–æ–∫–∞—è" if confidence > 0.8 else "—Å—Ä–µ–¥–Ω—è—è" if confidence > 0.6 else "–Ω–∏–∑–∫–∞—è"
                )
                
                # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏
                st.markdown("**–£—Ä–æ–≤–µ–Ω—å —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏:**")
                st.progress(float(confidence if result['prediction'] == 1 else 1 - confidence))
            
            with col_res3:
                st.metric(
                    label="–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏",
                    value=f"{result['probability']:.1%}" if result['prediction'] == 1 else f"{(1 - result['probability']):.1%}",
                    delta="–æ–ø–∞—Å–Ω–æ" if result['prediction'] == 1 and result['probability'] > 0.7 else "–Ω–æ—Ä–º–∞–ª—å–Ω–æ"
                )

            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è attention
            st.markdown("---")
            st.markdown('<div class="sub-header">üîç –ê–Ω–∞–ª–∏–∑ –≤–Ω–∏–º–∞–Ω–∏—è –º–æ–¥–µ–ª–∏</div>', unsafe_allow_html=True)
            st.pyplot(fig)
            
            # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–ª–æ–≤–∞—Ö
            with st.expander("üìã –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–ª–æ–≤–∞—Ö"):
                mean_attention = np.mean(attention_weights)
                st.write("**–°–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –º–æ–¥–µ–ª–∏:**")
                
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–ª–æ–≤–∞ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
                sorted_indices = np.argsort(attention_weights)[::-1]
                
                for i, idx in enumerate(sorted_indices[:5]):  # –¢–æ–ø-5 —Å–ª–æ–≤
                    word = words[idx]
                    weight = attention_weights[idx]
                    importance = "üî¥ –í—ã—Å–æ–∫–∞—è" if weight > mean_attention * 1.5 else "üü° –°—Ä–µ–¥–Ω—è—è" if weight > mean_attention else "üü¢ –ù–∏–∑–∫–∞—è"
                    
                    col_word, col_weight, col_imp = st.columns([2, 1, 1])
                    with col_word:
                        st.write(f"**{word}**")
                    with col_weight:
                        st.write(f"{weight:.4f}")
                    with col_imp:
                        st.write(importance)

    elif analyze_btn and not text_input:
        st.warning("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

except Exception as e:
    st.error(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}")
    st.info("üîß –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞")

# ===== –§–£–¢–ï–† =====
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: #666;'>"
    "üîç –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ | Powered by RuBERT | "
    "<a href='https://github.com/your-repo' target='_blank'>GitHub</a>"
    "</div>", 
    unsafe_allow_html=True
)